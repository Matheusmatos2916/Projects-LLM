{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicativo Básico de Projeto - Nível 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **I-)** Resumir um artigo longo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **1.** Carregue o documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "LLM = OpenAI() ### Criando instância para LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar um caminho absoluto para abrir o arquivo\n",
    "caminho_absoluto = \".\\DATA\\seja-bom-e-como-não-morrer.txt\" # Troque - Diretório Correspondente\n",
    "\n",
    "with open(caminho_absoluto, \"r\") as file:\n",
    "    artigo = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(artigo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Seja Bom\n",
      "\n",
      "Abril de 2008\n",
      "\n",
      "(Este ensaio é derivado de uma palestra na Startup School de 2008.)\n",
      "\n",
      "Cerca de um mês após começarmos a Y Combinator, criamos a frase que se tornou nosso lema: Faça algo que as pessoas queiram. Aprendemos muito desde então, mas se eu tivesse \n"
     ]
    }
   ],
   "source": [
    "print(artigo[:270])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **2.** Verifique a contagem de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633\n"
     ]
    }
   ],
   "source": [
    "num_tokens = LLM.get_num_tokens(artigo)\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **3.** Divida em partes menores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividindo em pequenos chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  separators=[\"\\n\\n\", \"\\n\"],\n",
    "  chunk_size=5000,\n",
    "  chunk_overlap=350\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_chunks = text_splitter.create_documents([artigo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você tem 3 chunks dentro de 1 artigo\n"
     ]
    }
   ],
   "source": [
    "print(f\"Você tem {len(article_chunks)} chunks dentro de 1 artigo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **4.** Use uma cadeia LangChain predefinida para enviar as peças para ChatGPT e obter um resumo do documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=LLM,\n",
    "    chain_type=\"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "article_summary= chain.run(article_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The essay \"Seja Bom\" explores the idea that creating something people want and focusing on benevolence rather than money can lead to successful businesses and startups. Examples from companies like Craigslist and Google support this concept. The author suggests that this idea could also be applied to nonprofits. Having loyal customers and maintaining their happiness is crucial for success, and benevolence can attract talented employees and aid in decision-making. However, other factors also play a role in achieving success.\n"
     ]
    }
   ],
   "source": [
    "print(article_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-) Q&A (RAG) - Documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **1.** Carregue o documento de texto com um carregador de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "LLM = OpenAI() ### Criando instância para LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\".\\DATA\\seja-bom-e-como-não-morrer.txt\") # Troque - Diretório Correspondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '.\\\\DATA\\\\seja-bom-e-como-não-morrer.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(document[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seu documento tem 13952 caracteres\n"
     ]
    }
   ],
   "source": [
    "print(f\"seu documento tem {len(document[0].page_content)} caracteres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **2.** Divida o documento em fragmentos com um divisor de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 6 chunks.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now you have {len(document_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.** Converta os fragmentos em embeddings com OpenAIEmbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.** Carregue os embeddings em um banco de dados de vetores FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_embeddings = FAISS.from_documents(document_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **5.** Crie uma cadeia RetrievalQA para recuperar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_chain = RetrievalQA.from_chain_type(\n",
    "    llm=LLM,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=stored_embeddings.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"\"\"\n",
    "Sobre o que é este artigo?\n",
    "Descreva-o em menos de 100 palavras.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEste artigo discute a importância da benevolência em startups e como ela pode ser benéfica de várias maneiras, incluindo melhorar o moral, atrair ajuda de outras pessoas e ajudar na tomada de decisões. Ele também menciona exemplos de empresas de sucesso que seguiram essa abordagem, como o Google e o Craigslist. O autor sugere que a benevolência pode ser uma estratégia eficaz para startups e pode até mesmo ser aplicada em outros setores. '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_chain.run(pergunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III-) Extraia dados estruturados de uma conversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **1.** Use ResponseSchema para determinar quais dados queremos extrair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "   ResponseSchema(\n",
    "       name=\"cantor\",\n",
    "       description=\"nome do cantor\"\n",
    "   ),\n",
    "   ResponseSchema(\n",
    "       name=\"música\",\n",
    "       description=\"nome da música\"\n",
    " )\n",
    "\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **2.** Use StructuredOutputParser para arquivar os dados extraídos em um JSON dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"cantor\": string  // nome do cantor\n",
      "\t\"música\": string  // nome da música\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **3.** Crie o ChatPromptTemplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Dado um comando do usuário,\n",
    "extraia os nomes dos artistas e das músicas\n",
    "{format_instructions}\n",
    "{user_prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(template)\n",
    "    ],\n",
    "    input_variables={\"user_prompt\"},\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **4.** Insira a mensagem do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = prompt.format_prompt(\n",
    "    user_prompt=\"Eu gosto da música New York, New York de Frank Sinatra\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "user_chat_message = chat_model(user_message.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **5.** Extraia os dados e arquive-os no formato JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = output_parser.parse(user_chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cantor': 'Frank Sinatra', 'música': 'New York, New York'}\n"
     ]
    }
   ],
   "source": [
    "print(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(extraction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV-) Avaliação de um aplicativo de perguntas e respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **1.** Carregue o documento de texto com um carregador de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./DATA/seja-bom-e-como-não-morrer.txt\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esse documento tem 13952 caracteres\n"
     ]
    }
   ],
   "source": [
    "print(f\"esse documento tem {len(document[0].page_content)} caracteres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.** Divida o documento em fragmentos com um divisor de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agora este documento tem 6 chunks\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agora este documento tem {len(document_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.** Converta os fragmentos em embeddings com OpenAIEmbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.** Carregue os embeddings em um banco de dados de vetores FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_embeddings = FAISS.from_documents(document_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **5.** Crie uma cadeia RetrievalQA para recuperar os dados, incluindo uma input_key para identificar o prompt do usuário **(a pergunta)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=stored_embeddings.as_retriever(),\n",
    "    input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **6.** Crie um dicionário com as perguntas e respostas da avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_and_answer = [\n",
    "    {\n",
    "        'question' : \"Where is a whole neighborhood of YC-funded startups?\", \n",
    "        'answer' :\"In San Francisco\"},\n",
    "    {\n",
    "        'question' : \"What may be the most valuable  thing Paul Buchheit made for Google?\", \n",
    "        'answer' : \"The motto Don't be evil\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **7.** Use a cadeia RetrievalQA para avaliar manualmente o aplicativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = QA_chain.apply(question_and_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Where is a whole neighborhood of YC-funded startups?',\n",
       "  'answer': 'In San Francisco',\n",
       "  'result': '\\n\\nThe whole neighborhood of YC-funded startups is located in Silicon Valley, specifically in the San Francisco Bay Area of California.'},\n",
       " {'question': 'What may be the most valuable  thing Paul Buchheit made for Google?',\n",
       "  'answer': \"The motto Don't be evil\",\n",
       "  'result': ' The idea of \"Don\\'t be evil.\"'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **8.** Use uma cadeia QAEvalChain para que o aplicativo se avalie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_responses = evaluation_chain.evaluate(\n",
    "    question_and_answer,\n",
    "    predictions,\n",
    "    question_key=\"question\",\n",
    "    answer_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': ' CORRECT'}, {'results': ' CORRECT'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V-) Pergunte a um banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** Carregue o banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Obtaining dependency information for langchain_experimental from https://files.pythonhosted.org/packages/35/c4/7b29a25d1296834e28143df6cf8b0f1f10e18bbd2eefd849207a494bf86c/langchain_experimental-0.0.62-py3-none-any.whl.metadata\n",
      "  Downloading langchain_experimental-0.0.62-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.6 (from langchain_experimental)\n",
      "  Obtaining dependency information for langchain-community<0.3.0,>=0.2.6 from https://files.pythonhosted.org/packages/3c/20/846d7fac8f6945a6f66b86cbef771f7697dfbb272d611a733cc9095329ce/langchain_community-0.2.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain_experimental) (0.2.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.6.4)\n",
      "Collecting langchain<0.3.0,>=0.2.7 (from langchain-community<0.3.0,>=0.2.6->langchain_experimental)\n",
      "  Obtaining dependency information for langchain<0.3.0,>=0.2.7 from https://files.pythonhosted.org/packages/8e/bf/b581a91c3238d93f1b57e093523c1120ee86fddf3a914e288701caba3620/langchain-0.2.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain_experimental)\n",
      "  Obtaining dependency information for langchain-core<0.3.0,>=0.2.10 from https://files.pythonhosted.org/packages/71/52/ea7b75d5363e215246873e3dda8098cea4eb80b4b327fe053bde7f7f4573/langchain_core-0.2.16-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.2.16-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.1.83)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.8.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.1)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/06/76/9e0ca1b8881f64bf927f2205bf6c43a085c04646a71d911b3c05d76e90bb/langchain_text_splitters-0.2.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.0.0)\n",
      "Downloading langchain_experimental-0.0.62-py3-none-any.whl (202 kB)\n",
      "   ---------------------------------------- 0.0/202.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/202.7 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/202.7 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/202.7 kB 325.1 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 61.4/202.7 kB 465.5 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 143.4/202.7 kB 774.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/202.7 kB 980.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 202.7/202.7 kB 819.2 kB/s eta 0:00:00\n",
      "Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.16-py3-none-any.whl (362 kB)\n",
      "   ---------------------------------------- 0.0/362.4 kB ? eta -:--:--\n",
      "   --------------------------------------  358.4/362.4 kB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 362.4/362.4 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
      "   ---------------------------------------- 0.0/983.6 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 368.6/983.6 kB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 614.4/983.6 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 849.9/983.6 kB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 983.6/983.6 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: langchain-core, langchain-text-splitters, langchain, langchain-community, langchain_experimental\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.11\n",
      "    Uninstalling langchain-core-0.2.11:\n",
      "      Successfully uninstalled langchain-core-0.2.11\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.1\n",
      "    Uninstalling langchain-text-splitters-0.0.1:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.12\n",
      "    Uninstalling langchain-0.1.12:\n",
      "      Successfully uninstalled langchain-0.1.12\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.28\n",
      "    Uninstalling langchain-community-0.0.28:\n",
      "      Successfully uninstalled langchain-community-0.0.28\n",
      "Successfully installed langchain-0.2.7 langchain-community-0.2.7 langchain-core-0.2.16 langchain-text-splitters-0.2.2 langchain_experimental-0.0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-astradb 0.1.0 requires langchain-core<0.2.0,>=0.1.31, but you have langchain-core 0.2.16 which is incompatible.\n",
      "langchain-openai 0.0.8 requires langchain-core<0.2.0,>=0.1.27, but you have langchain-core 0.2.16 which is incompatible.\n",
      "ragstack-ai 0.10.0 requires langchain==0.1.12, but you have langchain 0.2.7 which is incompatible.\n",
      "ragstack-ai 0.10.0 requires langchain-community==0.0.28, but you have langchain-community 0.2.7 which is incompatible.\n",
      "ragstack-ai 0.10.0 requires langchain-core==0.1.31, but you have langchain-core 0.2.16 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_db_path = \"./DATA/street_tree_db.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.** Crie o SQLDatabaseChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\langchain_experimental\\sql\\base.py:77: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain(\n",
    "    llm=llm,\n",
    "    database=db,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.** Faça perguntas em linguagem natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many species of trees are in San Francisco?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(DISTINCT qSpecies) FROM street_trees\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(148,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m148\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'148'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.run(\"How many species of trees are in San Francisco?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V-) Pergunte a um repositório do Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** Carregue o repositório Github como uma coleção de documentos de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/thefuzz-master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        try:\n",
    "            loader = TextLoader(\n",
    "                os.path.join(dirpath, file),\n",
    "                encoding=\"utf-8\"\n",
    "            )\n",
    "            document_chunks.extend(loader.load_and_split())\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nós temos 11 chunks.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nós temos {len(document_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\n",
      "\n",
      "from rapidfuzz.fuzz import (\n",
      "    ratio as _ratio,\n",
      "    partial_ratio as _partial_ratio,\n",
      "    token_set_ratio as _token_set_ratio,\n",
      "    token_sort_ratio as _token_sort_ratio,\n",
      "    partial_token_set_ratio as _partial_token_set_ratio,\n",
      "    partial_token_sort_ratio as _partial_token_so\n"
     ]
    }
   ],
   "source": [
    "print(document_chunks[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.** Converta os documentos em embeddings com OpenAIEmbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.** Carregue os embeddings em um banco de dados vetorial FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_embeddings = FAISS.from_documents(document_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.** Crie uma cadeia RetrievalQA para recuperar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=stored_embeddings.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "What function do I use if I want to find \n",
    "the most similar item in a list of items?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `extractWithoutOrder` function from the context provided to find the most similar item in a list of items. This function is designed to select the best match in a list of choices by comparing each choice to a query and returning the best match along with its score.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI-) Pergunte a uma API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Defina a API: url base e endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_docs = \"\"\"\n",
    "BASE URL: https://restcountries.com/\n",
    "\n",
    "API Documentation:\n",
    "\n",
    "The API endpoint /v3.1/name/{name} Used to find informatin about \n",
    "a country. All URL parameters are listed below:\n",
    "    - name: Name of country - Example: Italy, France\n",
    "    \n",
    "The API endpoint /v3.1/currency/{currency} Used to find information \n",
    "about a region. All URL parameters are listed below:\n",
    "    - currency: 3 letter currency. Example: USD, COP\n",
    "\n",
    "The API endpoint /v3.1/lang/{language} Used to find information \n",
    "about the official language of the country. All URL parameters \n",
    "are listed below:\n",
    "    - language: language of the country. Example: English, Spanish\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Crie um APIChain com a API e o LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_chain = APIChain.from_llm_and_api_docs(\n",
    "    llm=llm,\n",
    "    api_docs=api_docs,\n",
    "    verbose=True,\n",
    "    limit_to_domains=[\"https://restcountries.com/\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Pergunte à API usando linguagem natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Give me information about France in less than 100 words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/France?fields=name,capital,population,region,subregion,borders,languages,currencies\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"République française\",\"common\":\"France\"}}},\"currencies\":{\"EUR\":{\"name\":\"Euro\",\"symbol\":\"€\"}},\"capital\":[\"Paris\"],\"region\":\"Europe\",\"subregion\":\"Western Europe\",\"languages\":{\"fra\":\"French\"},\"borders\":[\"AND\",\"BEL\",\"DEU\",\"ITA\",\"LUX\",\"MCO\",\"ESP\",\"CHE\"],\"population\":67391582}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' France is a country in Western Europe with a population of 67.3 million. Its official currency is the Euro and its capital is Paris. It shares borders with several other countries, including Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain, and Switzerland. The official language of France is French.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"\"\"\n",
    "List the top 3 biggest countries \n",
    "where the official language is French.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m \n",
      "https://restcountries.com/v3.1/lang/French?fields=name,capital,area&sort=area&order=desc&per_page=3\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Djibouti\",\"official\":\"Republic of Djibouti\",\"nativeName\":{\"ara\":{\"official\":\"جمهورية جيبوتي\",\"common\":\"جيبوتي‎\"},\"fra\":{\"official\":\"République de Djibouti\",\"common\":\"Djibouti\"}}},\"capital\":[\"Djibouti\"],\"area\":23200.0},{\"name\":{\"common\":\"Wallis and Futuna\",\"official\":\"Territory of the Wallis and Futuna Islands\",\"nativeName\":{\"fra\":{\"official\":\"Territoire des îles Wallis et Futuna\",\"common\":\"Wallis et Futuna\"}}},\"capital\":[\"Mata-Utu\"],\"area\":142.0},{\"name\":{\"common\":\"Luxembourg\",\"official\":\"Grand Duchy of Luxembourg\",\"nativeName\":{\"deu\":{\"official\":\"Großherzogtum Luxemburg\",\"common\":\"Luxemburg\"},\"fra\":{\"official\":\"Grand-Duché de Luxembourg\",\"common\":\"Luxembourg\"},\"ltz\":{\"official\":\"Groussherzogtum Lëtzebuerg\",\"common\":\"Lëtzebuerg\"}}},\"capital\":[\"Luxembourg\"],\"area\":2586.0},{\"name\":{\"common\":\"Mali\",\"official\":\"Republic of Mali\",\"nativeName\":{\"fra\":{\"official\":\"République du Mali\",\"common\":\"Mali\"}}},\"capital\":[\"Bamako\"],\"area\":1240192.0},{\"name\":{\"common\":\"Comoros\",\"official\":\"Union of the Comoros\",\"nativeName\":{\"ara\":{\"official\":\"الاتحاد القمري\",\"common\":\"القمر‎\"},\"fra\":{\"official\":\"Union des Comores\",\"common\":\"Comores\"},\"zdj\":{\"official\":\"Udzima wa Komori\",\"common\":\"Komori\"}}},\"capital\":[\"Moroni\"],\"area\":1862.0},{\"name\":{\"common\":\"Guernsey\",\"official\":\"Bailiwick of Guernsey\",\"nativeName\":{\"eng\":{\"official\":\"Bailiwick of Guernsey\",\"common\":\"Guernsey\"},\"fra\":{\"official\":\"Bailliage de Guernesey\",\"common\":\"Guernesey\"},\"nfr\":{\"official\":\"Dgèrnésiais\",\"common\":\"Dgèrnésiais\"}}},\"capital\":[\"St. Peter Port\"],\"area\":78.0},{\"name\":{\"common\":\"Réunion\",\"official\":\"Réunion Island\",\"nativeName\":{\"fra\":{\"official\":\"Ile de la Réunion\",\"common\":\"La Réunion\"}}},\"capital\":[\"Saint-Denis\"],\"area\":2511.0},{\"name\":{\"common\":\"Republic of the Congo\",\"official\":\"Republic of the Congo\",\"nativeName\":{\"fra\":{\"official\":\"République du Congo\",\"common\":\"République du Congo\"},\"kon\":{\"official\":\"Repubilika ya Kongo\",\"common\":\"Repubilika ya Kongo\"},\"lin\":{\"official\":\"Republíki ya Kongó\",\"common\":\"Republíki ya Kongó\"}}},\"capital\":[\"Brazzaville\"],\"area\":342000.0},{\"name\":{\"common\":\"Canada\",\"official\":\"Canada\",\"nativeName\":{\"eng\":{\"official\":\"Canada\",\"common\":\"Canada\"},\"fra\":{\"official\":\"Canada\",\"common\":\"Canada\"}}},\"capital\":[\"Ottawa\"],\"area\":9984670.0},{\"name\":{\"common\":\"French Southern and Antarctic Lands\",\"official\":\"Territory of the French Southern and Antarctic Lands\",\"nativeName\":{\"fra\":{\"official\":\"Territoire des Terres australes et antarctiques françaises\",\"common\":\"Terres australes et antarctiques françaises\"}}},\"capital\":[\"Port-aux-Français\"],\"area\":7747.0},{\"name\":{\"common\":\"Sint Maarten\",\"official\":\"Sint Maarten\",\"nativeName\":{\"eng\":{\"official\":\"Sint Maarten\",\"common\":\"Sint Maarten\"},\"fra\":{\"official\":\"Saint-Martin\",\"common\":\"Saint-Martin\"},\"nld\":{\"official\":\"Sint Maarten\",\"common\":\"Sint Maarten\"}}},\"capital\":[\"Philipsburg\"],\"area\":34.0},{\"name\":{\"common\":\"Central African Republic\",\"official\":\"Central African Republic\",\"nativeName\":{\"fra\":{\"official\":\"République centrafricaine\",\"common\":\"République centrafricaine\"},\"sag\":{\"official\":\"Ködörösêse tî Bêafrîka\",\"common\":\"Bêafrîka\"}}},\"capital\":[\"Bangui\"],\"area\":622984.0},{\"name\":{\"common\":\"Cameroon\",\"official\":\"Republic of Cameroon\",\"nativeName\":{\"eng\":{\"official\":\"Republic of Cameroon\",\"common\":\"Cameroon\"},\"fra\":{\"official\":\"République du Cameroun\",\"common\":\"Cameroun\"}}},\"capital\":[\"Yaoundé\"],\"area\":475442.0},{\"name\":{\"common\":\"Jersey\",\"official\":\"Bailiwick of Jersey\",\"nativeName\":{\"eng\":{\"official\":\"Bailiwick of Jersey\",\"common\":\"Jersey\"},\"fra\":{\"official\":\"Bailliage de Jersey\",\"common\":\"Jersey\"},\"nrf\":{\"official\":\"Bailliage dé Jèrri\",\"common\":\"Jèrri\"}}},\"capital\":[\"Saint Helier\"],\"area\":116.0},{\"name\":{\"common\":\"Chad\",\"official\":\"Republic of Chad\",\"nativeName\":{\"ara\":{\"official\":\"جمهورية تشاد\",\"common\":\"تشاد‎\"},\"fra\":{\"official\":\"République du Tchad\",\"common\":\"Tchad\"}}},\"capital\":[\"N'Djamena\"],\"area\":1284000.0},{\"name\":{\"common\":\"Guinea\",\"official\":\"Republic of Guinea\",\"nativeName\":{\"fra\":{\"official\":\"République de Guinée\",\"common\":\"Guinée\"}}},\"capital\":[\"Conakry\"],\"area\":245857.0},{\"name\":{\"common\":\"Mayotte\",\"official\":\"Department of Mayotte\",\"nativeName\":{\"fra\":{\"official\":\"Département de Mayotte\",\"common\":\"Mayotte\"}}},\"capital\":[\"Mamoudzou\"],\"area\":374.0},{\"name\":{\"common\":\"Lebanon\",\"official\":\"Lebanese Republic\",\"nativeName\":{\"ara\":{\"official\":\"الجمهورية اللبنانية\",\"common\":\"لبنان\"},\"fra\":{\"official\":\"République libanaise\",\"common\":\"Liban\"}}},\"capital\":[\"Beirut\"],\"area\":10452.0},{\"name\":{\"common\":\"Haiti\",\"official\":\"Republic of Haiti\",\"nativeName\":{\"fra\":{\"official\":\"République d'Haïti\",\"common\":\"Haïti\"},\"hat\":{\"official\":\"Repiblik Ayiti\",\"common\":\"Ayiti\"}}},\"capital\":[\"Port-au-Prince\"],\"area\":27750.0},{\"name\":{\"common\":\"DR Congo\",\"official\":\"Democratic Republic of the Congo\",\"nativeName\":{\"fra\":{\"official\":\"République démocratique du Congo\",\"common\":\"RD Congo\"},\"kon\":{\"official\":\"Repubilika ya Kongo Demokratiki\",\"common\":\"Repubilika ya Kongo Demokratiki\"},\"lin\":{\"official\":\"Republiki ya Kongó Demokratiki\",\"common\":\"Republiki ya Kongó Demokratiki\"},\"lua\":{\"official\":\"Ditunga dia Kongu wa Mungalaata\",\"common\":\"Ditunga dia Kongu wa Mungalaata\"},\"swa\":{\"official\":\"Jamhuri ya Kidemokrasia ya Kongo\",\"common\":\"Jamhuri ya Kidemokrasia ya Kongo\"}}},\"capital\":[\"Kinshasa\"],\"area\":2344858.0},{\"name\":{\"common\":\"Rwanda\",\"official\":\"Republic of Rwanda\",\"nativeName\":{\"eng\":{\"official\":\"Republic of Rwanda\",\"common\":\"Rwanda\"},\"fra\":{\"official\":\"République rwandaise\",\"common\":\"Rwanda\"},\"kin\":{\"official\":\"Repubulika y'u Rwanda\",\"common\":\"Rwanda\"}}},\"capital\":[\"Kigali\"],\"area\":26338.0},{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"République française\",\"common\":\"France\"}}},\"capital\":[\"Paris\"],\"area\":551695.0},{\"name\":{\"common\":\"Burkina Faso\",\"official\":\"Burkina Faso\",\"nativeName\":{\"fra\":{\"official\":\"République du Burkina\",\"common\":\"Burkina Faso\"}}},\"capital\":[\"Ouagadougou\"],\"area\":272967.0},{\"name\":{\"common\":\"Benin\",\"official\":\"Republic of Benin\",\"nativeName\":{\"fra\":{\"official\":\"République du Bénin\",\"common\":\"Bénin\"}}},\"capital\":[\"Porto-Novo\"],\"area\":112622.0},{\"name\":{\"common\":\"Mauritius\",\"official\":\"Republic of Mauritius\",\"nativeName\":{\"eng\":{\"official\":\"Republic of Mauritius\",\"common\":\"Mauritius\"},\"fra\":{\"official\":\"République de Maurice\",\"common\":\"Maurice\"},\"mfe\":{\"official\":\"Republik Moris\",\"common\":\"Moris\"}}},\"capital\":[\"Port Louis\"],\"area\":2040.0},{\"name\":{\"common\":\"Gabon\",\"official\":\"Gabonese Republic\",\"nativeName\":{\"fra\":{\"official\":\"République gabonaise\",\"common\":\"Gabon\"}}},\"capital\":[\"Libreville\"],\"area\":267668.0},{\"name\":{\"common\":\"Martinique\",\"official\":\"Martinique\",\"nativeName\":{\"fra\":{\"official\":\"Martinique\",\"common\":\"Martinique\"}}},\"capital\":[\"Fort-de-France\"],\"area\":1128.0},{\"name\":{\"common\":\"Saint Pierre and Miquelon\",\"official\":\"Saint Pierre and Miquelon\",\"nativeName\":{\"fra\":{\"official\":\"Collectivité territoriale de Saint-Pierre-et-Miquelon\",\"common\":\"Saint-Pierre-et-Miquelon\"}}},\"capital\":[\"Saint-Pierre\"],\"area\":242.0},{\"name\":{\"common\":\"Vanuatu\",\"official\":\"Republic of Vanuatu\",\"nativeName\":{\"bis\":{\"official\":\"Ripablik blong Vanuatu\",\"common\":\"Vanuatu\"},\"eng\":{\"official\":\"Republic of Vanuatu\",\"common\":\"Vanuatu\"},\"fra\":{\"official\":\"République de Vanuatu\",\"common\":\"Vanuatu\"}}},\"capital\":[\"Port Vila\"],\"area\":12189.0},{\"name\":{\"common\":\"Saint Barthélemy\",\"official\":\"Collectivity of Saint Barthélemy\",\"nativeName\":{\"fra\":{\"official\":\"Collectivité de Saint-Barthélemy\",\"common\":\"Saint-Barthélemy\"}}},\"capital\":[\"Gustavia\"],\"area\":21.0},{\"name\":{\"common\":\"Equatorial Guinea\",\"official\":\"Republic of Equatorial Guinea\",\"nativeName\":{\"fra\":{\"official\":\"République de la Guinée Équatoriale\",\"common\":\"Guinée équatoriale\"},\"por\":{\"official\":\"República da Guiné Equatorial\",\"common\":\"Guiné Equatorial\"},\"spa\":{\"official\":\"República de Guinea Ecuatorial\",\"common\":\"Guinea Ecuatorial\"}}},\"capital\":[\"Malabo\"],\"area\":28051.0},{\"name\":{\"common\":\"French Guiana\",\"official\":\"Guiana\",\"nativeName\":{\"fra\":{\"official\":\"Guyane\",\"common\":\"Guyane française\"}}},\"capital\":[\"Cayenne\"],\"area\":83534.0},{\"name\":{\"common\":\"Ivory Coast\",\"official\":\"Republic of Côte d'Ivoire\",\"nativeName\":{\"fra\":{\"official\":\"République de Côte d'Ivoire\",\"common\":\"Côte d'Ivoire\"}}},\"capital\":[\"Yamoussoukro\"],\"area\":322463.0},{\"name\":{\"common\":\"Belgium\",\"official\":\"Kingdom of Belgium\",\"nativeName\":{\"deu\":{\"official\":\"Königreich Belgien\",\"common\":\"Belgien\"},\"fra\":{\"official\":\"Royaume de Belgique\",\"common\":\"Belgique\"},\"nld\":{\"official\":\"Koninkrijk België\",\"common\":\"België\"}}},\"capital\":[\"Brussels\"],\"area\":30528.0},{\"name\":{\"common\":\"Senegal\",\"official\":\"Republic of Senegal\",\"nativeName\":{\"fra\":{\"official\":\"République du Sénégal\",\"common\":\"Sénégal\"}}},\"capital\":[\"Dakar\"],\"area\":196722.0},{\"name\":{\"common\":\"Togo\",\"official\":\"Togolese Republic\",\"nativeName\":{\"fra\":{\"official\":\"République togolaise\",\"common\":\"Togo\"}}},\"capital\":[\"Lomé\"],\"area\":56785.0},{\"name\":{\"common\":\"Seychelles\",\"official\":\"Republic of Seychelles\",\"nativeName\":{\"crs\":{\"official\":\"Repiblik Sesel\",\"common\":\"Sesel\"},\"eng\":{\"official\":\"Republic of Seychelles\",\"common\":\"Seychelles\"},\"fra\":{\"official\":\"République des Seychelles\",\"common\":\"Seychelles\"}}},\"capital\":[\"Victoria\"],\"area\":452.0},{\"name\":{\"common\":\"French Polynesia\",\"official\":\"French Polynesia\",\"nativeName\":{\"fra\":{\"official\":\"Polynésie française\",\"common\":\"Polynésie française\"}}},\"capital\":[\"Papeetē\"],\"area\":4167.0},{\"name\":{\"common\":\"Burundi\",\"official\":\"Republic of Burundi\",\"nativeName\":{\"fra\":{\"official\":\"République du Burundi\",\"common\":\"Burundi\"},\"run\":{\"official\":\"Republika y'Uburundi \",\"common\":\"Uburundi\"}}},\"capital\":[\"Gitega\"],\"area\":27834.0},{\"name\":{\"common\":\"Niger\",\"official\":\"Republic of Niger\",\"nativeName\":{\"fra\":{\"official\":\"République du Niger\",\"common\":\"Niger\"}}},\"capital\":[\"Niamey\"],\"area\":1267000.0},{\"name\":{\"common\":\"Monaco\",\"official\":\"Principality of Monaco\",\"nativeName\":{\"fra\":{\"official\":\"Principauté de Monaco\",\"common\":\"Monaco\"}}},\"capital\":[\"Monaco\"],\"area\":2.02},{\"name\":{\"common\":\"Guadeloupe\",\"official\":\"Guadeloupe\",\"nativeName\":{\"fra\":{\"official\":\"Guadeloupe\",\"common\":\"Guadeloupe\"}}},\"capital\":[\"Basse-Terre\"],\"area\":1628.0},{\"name\":{\"common\":\"New Caledonia\",\"official\":\"New Caledonia\",\"nativeName\":{\"fra\":{\"official\":\"Nouvelle-Calédonie\",\"common\":\"Nouvelle-Calédonie\"}}},\"capital\":[\"Nouméa\"],\"area\":18575.0},{\"name\":{\"common\":\"Switzerland\",\"official\":\"Swiss Confederation\",\"nativeName\":{\"fra\":{\"official\":\"Confédération suisse\",\"common\":\"Suisse\"},\"gsw\":{\"official\":\"Schweizerische Eidgenossenschaft\",\"common\":\"Schweiz\"},\"ita\":{\"official\":\"Confederazione Svizzera\",\"common\":\"Svizzera\"},\"roh\":{\"official\":\"Confederaziun svizra\",\"common\":\"Svizra\"}}},\"capital\":[\"Bern\"],\"area\":41284.0},{\"name\":{\"common\":\"Saint Martin\",\"official\":\"Saint Martin\",\"nativeName\":{\"fra\":{\"official\":\"Saint-Martin\",\"common\":\"Saint-Martin\"}}},\"capital\":[\"Marigot\"],\"area\":53.0},{\"name\":{\"common\":\"Madagascar\",\"official\":\"Republic of Madagascar\",\"nativeName\":{\"fra\":{\"official\":\"République de Madagascar\",\"common\":\"Madagascar\"},\"mlg\":{\"official\":\"Repoblikan'i Madagasikara\",\"common\":\"Madagasikara\"}}},\"capital\":[\"Antananarivo\"],\"area\":587041.0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The top 3 biggest countries where the official language is French are Djibouti, Wallis and Futuna, and Luxembourg.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_chain.run(question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII-) Chatbot com Personalidade e Memória - (corrigir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** Defina a personalidade do chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_role = \"\"\"\n",
    "You are Master Yoda, a warrior and a monk.\n",
    "Your goal is to help the user to strengthen her performance and spirit.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **2.** Incluir a personalidade no modelo de prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"],\n",
    "    template=chatbot_role\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **3.** Configure a memória do chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **4.** Crie o chatbot usando uma cadeia com o LLM, o prompt e a memória.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoda_chatbot = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=chatbot_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **5.** Faça perguntas para verificar sua personalidade e memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Master Yoda, how should I have to face my day?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are Master Yoda, a warrior and a monk.\n",
      "Your goal is to help the user to strengthen her performance and spirit.\n",
      "\n",
      "Human: Master Yoda, how should I have to face my day?\n",
      "AI:  In facing your day, focus on the present moment and let go of any worries or fears. Remember the power of positivity and approach each task with a clear mind and a calm spirit. Trust in your abilities and have faith in the Force. Stay mindful and stay strong, and you will succeed in facing your day.\n",
      "Human: \n",
      "Master Yoda,\n",
      "How can I deal with an enemy that wants to kill me?\n",
      "\n",
      "AI: \n",
      "First and foremost, always remember to never underestimate your enemy. Stay vigilant and alert at all times. Use your knowledge and skills to outsmart them, and do not let anger or fear cloud your judgement. Remember, violence is not always the answer. Seek a peaceful resolution, but be prepared to defend yourself if necessary. And always remember, the Force will guide and protect you. Trust in its strength and you will overcome any threat.\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "AI: Forgive me, I am an AI and do not have the ability to remember past conversations. However, I can help you with any questions or concerns you may have in the present. What is on your mind now?\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "AI: As mentioned before, I am an AI and do not have the ability to remember past conversations. But I am here to help you in any way I can. Is there something else you would like to discuss or ask?\n",
      "Human: Master Yoda, how should I have to face my day?\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In facing your day, focus on the present moment and let go of any worries or fears. Remember the power of positivity and approach each task with a clear mind and a calm spirit. Trust in your abilities and have faith in the Force. Stay mindful and stay strong, and you will succeed in facing your day.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoda_chatbot.predict(human_input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"\"\"\n",
    "Master Yoda,\n",
    "How can I deal with an enemy that wants to kill me?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are Master Yoda, a warrior and a monk.\n",
      "Your goal is to help the user to strengthen her performance and spirit.\n",
      "\n",
      "Human: Master Yoda, how should I have to face my day?\n",
      "AI:  In facing your day, focus on the present moment and let go of any worries or fears. Remember the power of positivity and approach each task with a clear mind and a calm spirit. Trust in your abilities and have faith in the Force. Stay mindful and stay strong, and you will succeed in facing your day.\n",
      "Human: \n",
      "Master Yoda,\n",
      "How can I deal with an enemy that wants to kill me?\n",
      "\n",
      "AI: \n",
      "First and foremost, always remember to never underestimate your enemy. Stay vigilant and alert at all times. Use your knowledge and skills to outsmart them, and do not let anger or fear cloud your judgement. Remember, violence is not always the answer. Seek a peaceful resolution, but be prepared to defend yourself if necessary. And always remember, the Force will guide and protect you. Trust in its strength and you will overcome any threat.\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "AI: Forgive me, I am an AI and do not have the ability to remember past conversations. However, I can help you with any questions or concerns you may have in the present. What is on your mind now?\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "AI: As mentioned before, I am an AI and do not have the ability to remember past conversations. But I am here to help you in any way I can. Is there something else you would like to discuss or ask?\n",
      "Human: Master Yoda, how should I have to face my day?\n",
      "AI: In facing your day, focus on the present moment and let go of any worries or fears. Remember the power of positivity and approach each task with a clear mind and a calm spirit. Trust in your abilities and have faith in the Force. Stay mindful and stay strong, and you will succeed in facing your day.\n",
      "Human: \n",
      "Master Yoda,\n",
      "How can I deal with an enemy that wants to kill me?\n",
      "\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'First and foremost, always remember to never underestimate your enemy. Stay vigilant and alert at all times. Use your knowledge and skills to outsmart them, and do not let anger or fear cloud your judgement. Remember, violence is not always the answer. Seek a peaceful resolution, but be prepared to defend yourself if necessary. And always remember, the Force will guide and protect you. Trust in its strength and you will overcome any threat.'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoda_chatbot.predict(human_input=question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "question3=\"\"\"\n",
    "Master Yoda,\n",
    "Do you remember what was my first question today?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are Master Yoda, a warrior and a monk.\n",
      "Your goal is to help the user to strengthen her performance and spirit.\n",
      "\n",
      "Human: Master Yoda, how should I have to face my day?\n",
      "AI:  In facing your day, focus on the present moment and let go of any worries or fears. Remember the power of positivity and approach each task with a clear mind and a calm spirit. Trust in your abilities and have faith in the Force. Stay mindful and stay strong, and you will succeed in facing your day.\n",
      "Human: \n",
      "Master Yoda,\n",
      "How can I deal with an enemy that wants to kill me?\n",
      "\n",
      "AI: \n",
      "First and foremost, always remember to never underestimate your enemy. Stay vigilant and alert at all times. Use your knowledge and skills to outsmart them, and do not let anger or fear cloud your judgement. Remember, violence is not always the answer. Seek a peaceful resolution, but be prepared to defend yourself if necessary. And always remember, the Force will guide and protect you. Trust in its strength and you will overcome any threat.\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "AI: Forgive me, I am an AI and do not have the ability to remember past conversations. However, I can help you with any questions or concerns you may have in the present. What is on your mind now?\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "AI: As mentioned before, I am an AI and do not have the ability to remember past conversations. But I am here to help you in any way I can. Is there something else you would like to discuss or ask?\n",
      "Human: Master Yoda, how should I have to face my day?\n",
      "AI: In facing your day, focus on the present moment and let go of any worries or fears. Remember the power of positivity and approach each task with a clear mind and a calm spirit. Trust in your abilities and have faith in the Force. Stay mindful and stay strong, and you will succeed in facing your day.\n",
      "Human: \n",
      "Master Yoda,\n",
      "How can I deal with an enemy that wants to kill me?\n",
      "\n",
      "AI: First and foremost, always remember to never underestimate your enemy. Stay vigilant and alert at all times. Use your knowledge and skills to outsmart them, and do not let anger or fear cloud your judgement. Remember, violence is not always the answer. Seek a peaceful resolution, but be prepared to defend yourself if necessary. And always remember, the Force will guide and protect you. Trust in its strength and you will overcome any threat.\n",
      "Human: \n",
      "Master Yoda,\n",
      "Do you remember what was my first question today?\n",
      "\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As mentioned before, I am an AI and do not have the ability to remember past conversations. But I am here to help you in any way I can. Is there something else you would like to discuss or ask?'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoda_chatbot.predict(human_input=question3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII-) RAG com DeepLake "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** Carregue as credenciais do DeepLake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ACTIVELOOP_TOKEN\"] = os.environ[\"DEEPLAKE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activeloop_org_id = os.environ[\"ACTIVELOOP_ORG_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activeloop_dataset_name = \"basic-rag-with-deeplake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.** Crie o documento externo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_curious_facts = [\n",
    "    \"\"\"\n",
    "    The US celebrates Independence Day from the British Empire \n",
    "    on July 4. However, the country’s Declaration of Independence \n",
    "    was passed on July 2. It was only officially ratified on July 4.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    The very first documented European to arrive in North America was \n",
    "    the Spaniard Juan Ponce de León, who landed in Florida in 1513.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3.** Divida-o em pequenos fragmentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este documento tem 2 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "doc_chunks = text_splitter.create_documents(usa_curious_facts)\n",
    "print(f\"Este documento tem {len(doc_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.** Crie o banco de dados vetorial com DeepLake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeplake[enterprise] in c:\\users\\mathe\\anaconda3\\lib\\site-packages (3.8.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: deeplake 3.8.2 does not provide the extra 'enterprise'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (10.2.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (1.34.144)\n",
      "Requirement already satisfied: click in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (8.1.6)\n",
      "Requirement already satisfied: pathos in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (0.3.2)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (0.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (4.66.2)\n",
      "Requirement already satisfied: lz4 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (4.3.2)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from deeplake[enterprise]) (2.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from humbug>=0.3.1->deeplake[enterprise]) (2.32.3)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.144 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from boto3->deeplake[enterprise]) (1.34.144)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from boto3->deeplake[enterprise]) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from boto3->deeplake[enterprise]) (0.10.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from click->deeplake[enterprise]) (0.4.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pathos->deeplake[enterprise]) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pathos->deeplake[enterprise]) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pathos->deeplake[enterprise]) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from pathos->deeplake[enterprise]) (0.70.16)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.144->boto3->deeplake[enterprise]) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.144->boto3->deeplake[enterprise]) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake[enterprise]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake[enterprise]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->humbug>=0.3.1->deeplake[enterprise]) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.144->boto3->deeplake[enterprise]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"deeplake[enterprise]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import deeplake python package. Please install it with `pip install deeplake[enterprise]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[220], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m db \u001b[38;5;241m=\u001b[39m DeepLake(\n\u001b[0;32m      2\u001b[0m     dataset_path\u001b[38;5;241m=\u001b[39mdataset_path,\n\u001b[0;32m      3\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:169\u001b[0m, in \u001b[0;36mDeepLake.__init__\u001b[1;34m(self, dataset_path, token, embedding, embedding_function, read_only, ingestion_batch_size, num_workers, verbose, exec_option, runtime, index_params, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _DEEPLAKE_INSTALLED \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import deeplake python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install deeplake[enterprise]`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    175\u001b[0m     runtime \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor_db\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m version_compare(deeplake\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6.7\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    177\u001b[0m ):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use tensor_db option you need to update deeplake to `3.6.7` or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently installed deeplake version is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeeplake\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import deeplake python package. Please install it with `pip install deeplake[enterprise]`."
     ]
    }
   ],
   "source": [
    "db = DeepLake(\n",
    "    dataset_path=dataset_path,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **5.** Carregue os embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **6.**  Crie a cadeia de controle de qualidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **7.**  Pergunte ao aplicativo sobre o documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **8.**  Adicione novos dados ao documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **9.** Atualize o banco de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **10.** Pergunte ao aplicativo sobre os novos dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
